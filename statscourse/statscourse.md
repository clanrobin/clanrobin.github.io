## Stanford Stats Course

Stanford University has a self-paced statistics course run by Prof Trevor Hastie and Prof Robert Tibshirani.
The course covers a wide variety of statistical learning packages and shows how these tools can be implemented in R. I highly recommend it. To show my progress, I've added the R code that comes with the course with some of my own tweaks and my attempts at the questions at the end of each chapter.

For each chapter, I've listed an overview of what was covered and a link to the R code to demonstrate some of those topics. For the early chapters I've converted the original .R code to .Rmd for ease of viewing.

### Overview of Statistical Learning
Chapter 2 of the course, covering Regression Models, Dimensionality and Structured Models, Model Selection and Bias-Variance Tradeoff, Classification, and an introduction to R.
<!-- My R code on [StatsCourse_Ch2](/docs/ch2.html) -->

### Linear Regression
Chapter 3 covers: Simple Linear Regression, Hypothesis Testing and Confidence Intervals, Multiple Linear Regression, Extensions of the linear model and Linear Regression in R.
<!-- My R code on [StatsCourse_Ch3](/docs/ch3.html) -->

### Classification
Chapter 4 covers: Logistic Regression, Multivariate Logistic Regression, Case-control sampling and multi-class, Discriminat Analysis, Gaussian Discriminat Analysis (one and many variables), Quadratic Discriminant Analysis and Naive Bayes, Classification in R.
<!-- My R code on [StatsCourse_Ch4](/docs/ch4.html) -->

### Resampling Methods
Chapter 5 covers: Cross-Validation, K-fold Cross-Validation, the right and wrong way, The Bootstrap, Resampling in R.
<!-- My R code on [StatsCourse_Ch5](/docs/ch5.html) -->

### Linear Model Selection and Regularization
Chapter 6 covers: Best-Subset selection, Stepwise selection, Backward stepwise selection, Estimating test error, Validation and cross-validation, shrinkage methods and ridge regression, The Lasso, Tuning parameter selection, Dimension Reduction methods, Principal Components Regression and Partial Least Squares, Model selection in R.

My R code on [StatsCourse_Ch6](/docs/ch6.html)

### Moving Beyond Linearity
Chapter 7 covers: Polynomials and Step functions, Piecewise-Polynomials and Splines, Smoothing Splines, Generative Additive Models and Local Regression, Nonlinear functions in R.

My R code on [StatsCourse_Ch7](/docs/ch7.html)

### Tree-Based Methods
Chapter 8 covers: Tree-based methods, classification trees, Bagging and Random Forest, Boosting, Tree-based methods in R.

My R code on [StatsCourse_Ch8](/docs/ch8.html)

### Support Vector Machines
Chapter 9 covers: Optimal Separating Hyperplanes, Support Vector Classifier, Feature expansion and the SVM, Comparison with Logistic Regression, SVMs in R.

My R code on [StatsCourse_Ch9](/docs/ch9.html)

### Unsupervised Learning
Chapter 10 covers: Principal Components, Higher Order Principal Components, k-means Clustering, Hierarchical Clustering, Unsupervised in R.

My R code on [StatsCourse_Ch10](/docs/ch10.html)
